{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Prometheus\n",
    "\n",
    "The notebook handles the exercise part mentioned in the course, It progressively does the following,\n",
    "\n",
    "* Clone this repository\n",
    "* Downloads the prometheus\n",
    "* Prepares a simple prometheus.yml and starts prometheus\n",
    "* Compiles the [demo-metrics-producer](./demo-metrics-producer/) and starts 3 instances\n",
    "* Updates the prometheus.yml's scrape_configs for scraping the demo-metrics-producer\n",
    "* Downloads NodeExporter, starts it and update prometheus\n",
    "* Runs cAdvisor, update prometheus\n",
    "* Builds the custom Node Exporter service [cpu-metrics-exporter](./cpu-metrics-exporter/) and starts it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration parameters\n",
    "\n",
    "The following block list some of the parameters that are used across various cells,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR=\"/tmp/lfs-prometheus\"\n",
    "\n",
    "PROM_VERSION=\"2.49.1\"\n",
    "DEMO_VERSION=\"0.11.1\"\n",
    "NODEEXP_VERSION=\"1.7.0\"\n",
    "CADVISOR_VERSION=\"0.36.0\"\n",
    "CONSUL_VERSION=\"1.17.3\"\n",
    "BLACKBOX_EXPORTER_VERSION=\"0.24.0\"\n",
    "PUSHGATEWAY_VERSION=\"1.7.0\"\n",
    "ALERTMANAGER_VERSION=\"0.26.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "\n",
    "{\n",
    "    echo \"Cloning the repo\"\n",
    "    WORKDIR=$1\n",
    "    if [ ! -e ${WORKDIR}/.git ]; then \n",
    "        git clone https://github.com/ennc0d3-learn/lfs-prometheus ${WORKDIR} \n",
    "    else \n",
    "        cd ${WORKDIR} && git pull --rebase\n",
    "    fi\n",
    "    echo \"Ready to go, ${WORKDIR}!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup part \n",
    "\n",
    "Use this to stop if you want to cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash -s {WORKDIR}\n",
    "{\n",
    "    echo \"Stopping all processes and containers that are started\"\n",
    "    killall prometheus\n",
    "    killall node_exporter\n",
    "    killall consul\n",
    "    killall prometheus_demo_service\n",
    "    killall cpu-metric-exporter.py\n",
    "    killall blackbox_exporter\n",
    "    killall pushgateway alertmanager alertreceiver_webhook\n",
    "        \n",
    "    docker rm -f cadvisor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Prometheus\n",
    "\n",
    "- Downloads prometheus\n",
    "- Updates the scrape_config\n",
    "- Starts the prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s  {WORKDIR} {PROM_VERSION}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    PROM_VERSION=$2\n",
    "    cd ${WORKDIR}\n",
    "    wget -q https://github.com/prometheus/prometheus/releases/download/v${PROM_VERSION}/prometheus-${PROM_VERSION}.linux-amd64.tar.gz\n",
    "    tar -zxf prometheus-${PROM_VERSION}.*.gz\n",
    "    rm -f prometheus-${PROM_VERSION}.*.gz\n",
    "    echo \"Downloaded prometheus ${PROM_VERSION}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the scrape config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {PROM_VERSION}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    PROM_VERSION=$2\n",
    "    prometheus_dir=${WORKDIR}/prometheus-${PROM_VERSION}*\n",
    "    cat > ${prometheus_dir}/prometheus.yml <<-EOD\n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "EOD\n",
    "echo \"Created the prometheus.yml\"\n",
    "cat ${prometheus_dir}/prometheus.yml\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    PROM_VERSION=$2\n",
    "    cd $WORKDIR/prometheus-*/\n",
    "    killall prometheus\n",
    "    ./prometheus >/dev/null &\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and start the demo service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {DEMO_VERSION}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    DEMO_VERSION=${2:-0.11.1}\n",
    "    cd $WORKDIR\n",
    "    echo \"Downloading the demo service version ${DEMO_VERSION}\"\n",
    "    wget -q https://github.com/juliusv/prometheus_demo_service/releases/download/${DEMO_VERSION}/prometheus_demo_service-${DEMO_VERSION}.linux-amd64\n",
    "    \n",
    "    chmod +x ./prometheus_demo_service-${DEMO_VERSION}.linux-amd64\n",
    "    mv ./prometheus_demo_service-${DEMO_VERSION}.linux-amd64 ./prometheus_demo_service\n",
    "    \n",
    "    echo \"Starting the demo service(3) instances\"\n",
    "    \n",
    "    killall prometheus_demo_service\n",
    "    \n",
    "    ./prometheus_demo_service -listen-address=\":10001\" > /dev/null 2>&1 &\n",
    "    ./prometheus_demo_service -listen-address=\":10002\" > /dev/null 2>&1 &\n",
    "    ./prometheus_demo_service -listen-address=\":10003\" > /dev/null 2>&1 &\n",
    "    \n",
    "    echo \"Demo instances are running\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the config and refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing node exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {NODEEXP_VERSION}\n",
    "{\n",
    "    cleanup() {\n",
    "        trap - INT TERM\n",
    "        echo \"Cleaning up the node_exporter\"\n",
    "        killall node_exporter\n",
    "        exit 1\n",
    "    }\n",
    "    \n",
    "    trap cleanup INT TERM\n",
    "    \n",
    "    WORKDIR=$1\n",
    "    NODEEXP_VERSION=${2:-1.7.0}\n",
    "    startNodeExporter() {\n",
    "        cd $WORKDIR\n",
    "        wget -q https://github.com/prometheus/node_exporter/releases/download/v${NODEEXP_VERSION}/node_exporter-${NODEEXP_VERSION}.linux-amd64.tar.gz -O node_exporter.tgz\n",
    "        tar -zxf node_exporter.tgz\n",
    "        chmod +x ./node_exporter*/node_exporter\n",
    "        killall node_exporter\n",
    "        ./node_exporter*/node_exporter & > /dev/null\n",
    "    }\n",
    "    echo \"Download and start the exporter\"\n",
    "    startNodeExporter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update scrape_config and reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install/Run cAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {CADVISOR_VERSION}\n",
    "{\n",
    "    WORKDIR=$1\n",
    "    CADVISOR_VERSION=${2:-\"0.36.0\"}\n",
    "    \n",
    "    cleanup() {\n",
    "        trap - INT TERM\n",
    "        echo \"Stopping cAdvisor\"\n",
    "        docker rm -f cadvisor\n",
    "        exit 1\n",
    "    }\n",
    "    \n",
    "    startCadvisor() {\n",
    "        docker rm -f cadvisor\n",
    "        docker run \\\n",
    "        --volume=/:/rootfs:ro \\\n",
    "        --volume=/var/run:/var/run:ro \\\n",
    "        --volume=/sys:/sys:ro \\\n",
    "        --volume=/var/lib/docker/:/var/lib/docker:ro \\\n",
    "        --volume=/dev/disk/:/dev/disk:ro \\\n",
    "        --publish=8080:8080 \\\n",
    "        --detach=true \\\n",
    "        --name=cadvisor \\\n",
    "        --privileged \\\n",
    "        --device=/dev/kmsg \\\n",
    "        gcr.io/cadvisor/cadvisor:v${CADVISOR_VERSION}\n",
    "    }\n",
    "    \n",
    "    trap cleanup INT TERM\n",
    "    startCadvisor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Udpdate scrape_config and refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Custom NodeExporter\n",
    "\n",
    "We write a custom node exporter in Python, see [cpu-metrics-exporter](./cpu-metrics-exporter/), Here we use psutil to read the\n",
    "cpu_usage for all modes and use the ConstantMetricFamily to expose them in Prometheus'es exposition format. The production of \n",
    "the metrics data happens with scrape interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the CPU Metrics Exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "{\n",
    "    WORKDIR=$1\n",
    "    cd $WORKDIR/cpu-metrics-exporter\n",
    "    killall cpu-metric-exporter.py\n",
    "    poetry shell\n",
    "    python3 ./cpu-metric-exporter.py &\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update and refresh prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "EOD\n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "      metric_relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__name__]\n",
    "          regex: '(demo_|http_).*'\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "EOD\n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Discovery\n",
    "\n",
    "Though the above method is good for a small number of services, it is not practical for a large number of services. In large-scale systems, we need a way to discover new services automatically, without having to update the Prometheus configuration file every time a new service is added or removed. There are several ways to achieve this, including:\n",
    "\n",
    "    - File-based service discovery\n",
    "    - Kubernetes \n",
    "    - Consul\n",
    "    - Cloud Provider based\n",
    "\n",
    "In this example, we are going to use consul for service discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {CONSUL_VERSION} \n",
    "{\n",
    "    WORKDIR=$1\n",
    "    CONSUL_VERSION=${2:-1.17.3}\n",
    "    cd ${WORKDIR}\n",
    "    echo \"Downloading consul ${CONSUL_VERSION} to ${WORKDIR}\"\n",
    "    wget -q https://releases.hashicorp.com/consul/${CONSUL_VERSION}/consul_${CONSUL_VERSION}_linux_amd64.zip\n",
    "    unzip -u -qq consul_${CONSUL_VERSION}_linux_amd64.zip\n",
    "    rm -f consul_${CONSUL_VERSION}_linux_amd64.zip\n",
    "    \n",
    "    chmod +x ./consul\n",
    "    \n",
    "    cat > ./demo-service.json <<-EOD\n",
    "{\n",
    "    \"services\":\n",
    "    [\n",
    "        {\"id\":\"demo1\",\"name\":\"demo\",\"address\":\"127.0.0.1\",\"port\":10001},\n",
    "        {\"id\":\"demo2\",\"name\":\"demo\",\"address\":\"127.0.0.1\",\"port\":10002},\n",
    "        {\"id\":\"demo3\",\"name\":\"demo\",\"address\":\"127.0.0.1\",\"port\":10003}\n",
    "    ]\n",
    "}\n",
    "EOD\n",
    "    killall consul\n",
    "    \n",
    "    ./consul agent -dev -config-dir=./demo-service.json > /dev/null 2>&1 &\n",
    "    echo \"Started consul\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add consul to the scrape configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "      metric_relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__name__]\n",
    "          regex: '(demo_|http_).*'\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "    - job_name: 'consul-sd-demo'\n",
    "      consul_sd_configs:\n",
    "        - server: 'localhost:8500'\n",
    "      relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__meta_consul_service]\n",
    "          regex: demo\n",
    "\n",
    "EOD\n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using File based discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    echo \"Updating the prometheus.yml to include file_sd_configs\"\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "      metric_relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__name__]\n",
    "          regex: '(demo_|http_).*'\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "    - job_name: 'consul-sd-demo'\n",
    "      consul_sd_configs:\n",
    "        - server: 'localhost:8500'\n",
    "      relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__meta_consul_service]\n",
    "          regex: demo\n",
    "    - job_name: 'file-sd-demo'\n",
    "      file_sd_configs:\n",
    "        - files:\n",
    "            - 'targets.yml'\n",
    "\n",
    "EOD\n",
    "\n",
    "    # Create the targets.yml\n",
    "    echo \"Creating the targets.yml file\"\n",
    "    cd $WORKDIR/prometheus-*/\n",
    "    cat > targets.yml <<-EOD\n",
    "- targets:\n",
    "    - localhost:10001\n",
    "    - localhost:10002\n",
    "  labels:\n",
    "    env: production\n",
    "- targets:\n",
    "    - localhost:10003\n",
    "  labels:\n",
    "    env: staging\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlackBox Exporter\n",
    "Instead of the target providing data, we can probe the target externally using protocols like HTTP, TCP, DNS, etc. The prometheus service discovery provides the targets to the BlackBox Exporter which then scrapes the target, here some relabelling is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {BLACKBOX_EXPORTER_VERSION} \n",
    "{\n",
    "    WORKDIR=$1\n",
    "    VERSION=${2:-0.24.0}\n",
    "    cd ${WORKDIR}\n",
    "    echo \"Downloading blackbox_exporter ${VERSION} to ${WORKDIR}\"\n",
    "    wget -q https://github.com/prometheus/blackbox_exporter/releases/download/v${VERSION}/blackbox_exporter-${VERSION}.linux-amd64.tar.gz\n",
    "    tar zxf blackbox_exporter-${VERSION}.linux-amd64.tar.gz\n",
    "    rm -f blackbox_exporter-${VERSION}.linux-amd64\n",
    "    \n",
    "    cd ./blackbox_exporter-${VERSION}.linux-amd64\n",
    "    \n",
    "    cat > ./blackbox.yml <<-EOD\n",
    "modules:\n",
    "    http_2xx:\n",
    "        prober: http\n",
    "        timeout: 2s\n",
    "        http:\n",
    "            valid_http_versions: [ \"HTTP/1.1\", \"HTTP/2\" ]\n",
    "            valid_status_codes: []  # Defaults to 2xx\n",
    "            method: GET\n",
    "            preferred_ip_protocol: \"ip4\"  # defaults to \"ip6\"\n",
    "EOD\n",
    "    killall blackbox_exporter\n",
    "    \n",
    "    ./blackbox_exporter > /dev/null 2>&1 &\n",
    "    echo \"Started blackbox_exporter, http://localhost:9115/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the scrape config to probe some websites using blackbox exporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    echo \"Updating the prometheus.yml to include blackbox_exporter\"\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "      metric_relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__name__]\n",
    "          regex: '(demo_|http_).*'\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "    - job_name: 'consul-sd-demo'\n",
    "      consul_sd_configs:\n",
    "        - server: 'localhost:8500'\n",
    "      relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__meta_consul_service]\n",
    "          regex: demo\n",
    "    - job_name: 'file-sd-demo'\n",
    "      file_sd_configs:\n",
    "        - files:\n",
    "            - 'targets.yml'\n",
    "            \n",
    "    - job_name: 'blackbox'\n",
    "      metrics_path: /probe\n",
    "      params:\n",
    "        module: [http_2xx]\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - http://prometheus.io\n",
    "            - https://prometheus.io\n",
    "            - http://example.com:8080\n",
    "      relabel_configs:\n",
    "        - source_labels: [__address__]\n",
    "          target_label: __param_target\n",
    "        - source_labels: [__param_target]\n",
    "          target_label: instance\n",
    "        - target_label: __address__\n",
    "          replacement: localhost:9115\n",
    "            \n",
    "EOD\n",
    "\n",
    "    # Create the targets.yml\n",
    "    echo \"Creating the targets.yml file\"\n",
    "    cd $WORKDIR/prometheus-*/\n",
    "    cat > targets.yml <<-EOD\n",
    "- targets:\n",
    "    - localhost:10001\n",
    "    - localhost:10002\n",
    "  labels:\n",
    "    env: production\n",
    "- targets:\n",
    "    - localhost:10003\n",
    "  labels:\n",
    "    env: staging\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PushGateway\n",
    "\n",
    "Its the way for ephemeral jobs to send metric data that get persisted until the next write, the prometheus server scrapes from the PushGateway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing PushGateway\n",
    "https://github.com/prometheus/pushgateway/releases/download/v1.7.0/pushgateway-1.7.0.linux-amd64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {PUSHGATEWAY_VERSION} \n",
    "{\n",
    "    set -x\n",
    "    WORKDIR=$1\n",
    "    VERSION=${2:-1.7.0}\n",
    "    cd ${WORKDIR}\n",
    "    echo \"Downloading PushGateweay ${VERSION} to ${WORKDIR}\"\n",
    "    wget -q https://github.com/prometheus/pushgateway/releases/download/v${VERSION}/pushgateway-${VERSION}.linux-amd64.tar.gz\n",
    "    tar zxf pushgateway-${VERSION}.linux-amd64.tar.gz\n",
    "    \n",
    "    cd ./pushgateway-${VERSION}.linux-amd64\n",
    "    \n",
    "    killall pushgateway\n",
    "    \n",
    "    ./pushgateway > /dev/null 2>&1 &\n",
    "    echo \"Started pushgateway, http://localhost:9091/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update scrape config and restart prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "(\n",
    "    echo \"Updating the prometheus.yml to include pushgateway\"\n",
    "    WORKDIR=$1\n",
    "    cat > ${WORKDIR}/prometheus-*/prometheus.yml <<-EOD \n",
    "global:\n",
    "    scrape_interval: 5s\n",
    "    evaluation_interval: 5s\n",
    "scrape_configs:\n",
    "    - job_name: 'prometheus'\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9090']\n",
    "    - job_name: 'demo-service'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:10001\n",
    "            - localhost:10002\n",
    "            - localhost:10003\n",
    "      metric_relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__name__]\n",
    "          regex: '(demo_|http_).*'\n",
    "    - job_name: 'node_exporter'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:9100\n",
    "    - job_name: 'cadvisor'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8080\n",
    "    - job_name: 'cpu-metrics'\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - localhost:8100\n",
    "    - job_name: 'consul-sd-demo'\n",
    "      consul_sd_configs:\n",
    "        - server: 'localhost:8500'\n",
    "      relabel_configs:\n",
    "        - action: keep\n",
    "          source_labels: [__meta_consul_service]\n",
    "          regex: demo\n",
    "    - job_name: 'file-sd-demo'\n",
    "      file_sd_configs:\n",
    "        - files:\n",
    "            - 'targets.yml'\n",
    "            \n",
    "    - job_name: 'blackbox'\n",
    "      metrics_path: /probe\n",
    "      params:\n",
    "        module: [http_2xx]\n",
    "      static_configs:\n",
    "        - targets:\n",
    "            - http://prometheus.io\n",
    "            - https://prometheus.io\n",
    "            - http://example.com:8080\n",
    "      relabel_configs:\n",
    "        - source_labels: [__address__]\n",
    "          target_label: __param_target\n",
    "        - source_labels: [__param_target]\n",
    "          target_label: instance\n",
    "        - target_label: __address__\n",
    "          replacement: localhost:9115\n",
    "          \n",
    "    - job_name: 'pushgateway'\n",
    "      honor_labels: true\n",
    "      static_configs:\n",
    "        - targets: ['localhost:9091']\n",
    "            \n",
    "EOD\n",
    "\n",
    "    # Create the targets.yml\n",
    "    echo \"Creating the targets.yml file\"\n",
    "    cd $WORKDIR/prometheus-*/\n",
    "    cat > targets.yml <<-EOD\n",
    "- targets:\n",
    "    - localhost:10001\n",
    "    - localhost:10002\n",
    "  labels:\n",
    "    env: production\n",
    "- targets:\n",
    "    - localhost:10003\n",
    "  labels:\n",
    "    env: staging\n",
    "EOD\n",
    "    \n",
    "    # Send signal to reaload\n",
    "    killall -HUP prometheus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate an batch job that pushes metrics to the pushgateway\n",
    "%%bash -s WORKDIR\n",
    "{\n",
    "curl --data-binary @- http://localhost:9091/metrics/job/demo_batch_job <<EOF\n",
    "# TYPE demo_batch_job_last_successful_run_timestamp_seconds gauge\n",
    "# HELP demo_batch_job_last_successful_run_timestamp_seconds The Unix timestampin seconds of the last successful batch job run.\n",
    "demo_batch_job_last_successful_run_timestamp_seconds $(date +%s)\n",
    "# TYPE demo_batch_job_last_run_timestamp_seconds gauge\n",
    "# HELP demo_batch_job_last_run_timestamp_seconds The Unix timestamp in seconds of the last successful batch job run.\n",
    "demo_batch_job_last_run_timestamp_seconds $(date +%s)\n",
    "# TYPE demo_batch_job_users_deleted gauge\n",
    "# HELP demo_batch_job_users_deleted How many userswere deleted in the lastbatch job run.\n",
    "demo_batch_job_users_deleted $RANDOM\n",
    "EOF\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete the deprovisioned batch metrics, Delete the group from PushGateway\n",
    "curl -XDELETE http://localhost:9091/metrics/job/demo_batch_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AlertManager\n",
    "\n",
    "We will use Prometheues in HA and AlertManager in HA for redundancy, the instances of AlertManager receives alerts from the prometheus servers. The AlertManager instances uses consensus mechanism and notification fired message as gossip, in case of network partition the\n",
    "alerts are atleast fired once, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR} {ALERTMANAGER_VERSION} \n",
    "{\n",
    "    WORKDIR=$1\n",
    "    VERSION=${2:-0.26.0}\n",
    "    cd ${WORKDIR}\n",
    "    echo \"Downloading alertmanager ${VERSION} to ${WORKDIR}\"\n",
    "    wget -q https://github.com/prometheus/alertmanager/releases/download/v${VERSION}/alertmanager-${VERSION}.linux-amd64.tar.gz\n",
    "    tar zxf alertmanager-${VERSION}.linux-amd64.tar.gz\n",
    "    \n",
    "    cd ./alertmanager-${VERSION}.linux-amd64\n",
    "    \n",
    "    cat > ./alertmanager.yml <<-EOD\n",
    "route:\n",
    "    group_by: ['alertname', 'job']\n",
    "    group_wait: \"30s\"\n",
    "    group_interval: \"5m\"\n",
    "    repeat_interval: \"3h\"\n",
    "    receiver: 'test-receiver-slack'\n",
    "    routes:\n",
    "        - match:\n",
    "            severity: critical\n",
    "          receiver: 'test-receiver-webhook'\n",
    "    \n",
    "receivers:\n",
    "    - name: test-receiver-slack\n",
    "      slack_configs:\n",
    "        - api_url: \"https://hooks.slack.com/services/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\"\n",
    "          username: 'Slack AlertBot'\n",
    "          channel: '#lfs-alertmanager'\n",
    "          send_resolved: true\n",
    "    # Make sure the alertreciever_webhook is running      \n",
    "    - name: test-receiver-webhook\n",
    "      webhook_configs:\n",
    "        - url: http://localhost:9595/\n",
    "                    \n",
    "    \n",
    "EOD\n",
    "    killall alertmanager alertreceiver_webhook.py\n",
    "    \n",
    "    ./alertmanager > /dev/null 2>&1 &\n",
    "    echo \"Started alertmanager, http://localhost:9093/\"\n",
    "    \n",
    "    echo \"Starting the webhook receiver\"\n",
    "    ./alertreceiver_webhook.py > /dev/null 2>&1 &\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add alerting_rules and relaod Proemtheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "{\n",
    "prometheus_cfg=${WORKDIR}/prometheus-*/prometheus.yml\n",
    "WORKDIR=$1\n",
    "if grep \"alerting_rules.yml\" $prometheus_cfg; then\n",
    "    echo \"The alerting rules are already included\"\n",
    "else\n",
    "    cat >> $prometheus_cfg <<-EOD\n",
    "rule_files:\n",
    "    - alerting_rules.yml\n",
    "EOD\n",
    "\n",
    "cd ${WORKDIR}/prometheus-*/\n",
    "cat > alerting_rules.yml <<-EOD\n",
    "groups:\n",
    "- name: demo-service-alerts\n",
    "rules:\n",
    "- alert: Many5xxErrors\n",
    "  expr: |\n",
    "    sum by(path, instance, job) (\n",
    "      rate(demo_api_request_duration_seconds_count{status=~\"5..\",job=\"demo\"}[\"1m\"])\n",
    "    )\n",
    "    /\n",
    "    sum by(path, instance, job) (\n",
    "        rate(demo_api_request_duration_seconds_count{job=\"demo\"}[\"1m\"])\n",
    "    ) * 100 > 0.5\n",
    "    \n",
    "for: \"30s\"\n",
    "labels:\n",
    "    severity: critical\n",
    "annotations:\n",
    "    description: \"The 5xx error rate for path {{$labels.path}} on {{$labels.instance}} is {{$value}}%.\"\n",
    "EOD\n",
    "\n",
    "killall -HUP prometheus\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Rules\n",
    "It is to run expensive queries and aggregate the metrics in higher-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {WORKDIR}\n",
    "{\n",
    "    set -x\n",
    "    WORKDIR=$1\n",
    "    echo \"Creating the recording rules file\"\n",
    "    prometheus_cfg=${WORKDIR}/prometheus-*/prometheus.yml\n",
    "    cd ${WORKDIR}/prometheus-*\n",
    "    cat > recording_rules.yml <<-EOD\n",
    "groups:\n",
    "    - name: demo-service\n",
    "        rules: \n",
    "            - record:\n",
    "            job: demo_api_request_duration_seconds_count:rate5m \n",
    "            expr:|\n",
    "                sum by(job) (rate(demo_api_request_duration_seconds_count[\"5m\"]))\n",
    "EOD\n",
    "    \n",
    "    echo \"Add the recording rule to $prometheus_cfg\"\n",
    "    if ! grep -q \"recording_rules.yml\" $prometheus_cfg; then\n",
    "        sed -i '/alerting_rules.yml/a\\    - recording_rules.yml' $prometheus_cfg\n",
    "    fi\n",
    "    \n",
    "    killall -HUP prometheus\n",
    "    \n",
    "}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the recorded query\n",
    "\n",
    "Assuming the setup is working, we should be able to query,\n",
    "```\n",
    "job:demo_api_request_duration_seconds_count:rate5m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prometheus on Kuberenetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install k8s using kubeadm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "{\n",
    "    echo \"Run the following as sudo\"\n",
    "    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -cat <<EOF >/etc/apt/sources.list.d/kubernetes.list\n",
    "deb http://apt.kubernetes.io/ kubernetes-jammy main\n",
    "EOF\n",
    "    apt-get update\n",
    "    apt-get install -y kubelet kubeadm kubectl\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the cluster\n",
    "- Turn of the swap\n",
    "- kubeadm init\n",
    "- Copy the admin.conf to ~/.kube/config # Chown the file to user\n",
    "- kubectl taint nodes --all node-role.kubernetes.io/master- (# As this is single node, remove taint)\n",
    "- Install the cluster network plugin (weavnet or calico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Storage - LTS\n",
    "\n",
    "- Influx Db ( slow,)\n",
    "- Thanos (Side Car, reuses the tsdb blocks and sends them to Storage(minio/s3..), Thanos Store(reads them and makes the series ready), Thanos Query)\n",
    "- Cortex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring and Debugging Prometheus\n",
    "\n",
    "- Meta Prometheus\n",
    "- Use prometheus'es metrics and run alerting\n",
    "\n",
    "#### Debugging/Profiling\n",
    "API /debug/pprof/profile, /debug/pprof/heap, /debug/pprof/goroutine?debug=2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-q7EMUs0i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
